{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4842ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import scanpy as sc\n",
    "from torchvision.datasets.folder import default_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac81473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stainaug import Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5801f29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde5a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76235ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from violet.utils.dataloaders import listfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef0c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = list(listfiles('../data/st/pdac_ffpe_07292021/train/HT270P1_S1H1Fs5U1/', regex='.jpeg$'))\n",
    "len(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe956b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = default_loader(fps[70])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153e5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = Augmentor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df458559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a33e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(augmentor.augment_HE(np.asarray(img)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a2b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from violet.utils.dataloaders import dino_he_transform_with_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b31382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dino_he_transform_with_aug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c584c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddf8fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = default_loader(fps[-1])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fdb34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = default_loader(fps[-10])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce66ddec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for x in range(10):\n",
    "    plt.imshow(rearrange(t(img).numpy(), 'c h w -> h w c'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03135f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = default_loader(fps[40])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de05b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(10):\n",
    "    tim = t(img).numpy()\n",
    "    print(np.min(tim), np.max(tim))\n",
    "    plt.imshow(rearrange(tim, 'c h w -> h w c'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f54ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c4d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from violet.utils.dino_utils import HE_color_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a487e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute new means and stds\n",
    "tcia_fps = sorted(listfiles('/data/tcia/PDA_preprocessed_small_raw/', regex=r'.jpeg$'))\n",
    "inhouse_fps = sorted(listfiles('../data/st/pdac_ffpe_07292021/train/', regex=r'.jpeg$'))\n",
    "tcia_v_fps = sorted(listfiles('/data/tcia/PDA_preprocessed_small/', regex=r'.jpeg$'))\n",
    "inhouse_v_fps = sorted(listfiles('../data/st/pdac_ffpe_normalized/train/', regex=r'.jpeg$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6800cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9368a216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c920f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from violet.utils.dino_utils import HE_color_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c19f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb10937",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = tcia_fps[10]\n",
    "img = Image.open(fp)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f343f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "'PIL' in str(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8b50ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = HE_color_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03917867",
   "metadata": {},
   "outputs": [],
   "source": [
    "t(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a9056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a3c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = torchvision.transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2800c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = to_tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e76d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(img, torch.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c525eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa38cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = t(img)\n",
    "aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43899aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pil = torchvision.transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe917791",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pil(aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eeb8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e0dbe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef0151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_means, sum_stds = np.asarray([0., 0., 0.]), np.asarray([0., 0., 0.])\n",
    "n = 1000\n",
    "ct = HE_color_transform()\n",
    "for fp in np.random.choice(tcia_fps, size=n):\n",
    "    img = default_loader(fp)\n",
    "    img = r(img)\n",
    "    img = hec(img)\n",
    "#     img = img.numpy()\n",
    "    sum_means += np.mean(rearrange(np.asarray(img), 'c h w -> (h w) c'), axis=0)\n",
    "    sum_stds += np.std(rearrange(np.asarray(img), 'c h w -> (h w) c'), axis=0)\n",
    "sum_means / n, sum_stds / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfd0950",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_means, sum_stds = np.asarray([0., 0., 0.]), np.asarray([0., 0., 0.])\n",
    "n = 1000\n",
    "ct = HE_color_transform()\n",
    "for fp in np.random.choice(inhouse_fps, size=n):\n",
    "    img = default_loader(fp)\n",
    "    img = r(img)\n",
    "    img = hec(img)\n",
    "#     img = img.numpy()\n",
    "    sum_means += np.mean(rearrange(np.asarray(img), 'c h w -> (h w) c'), axis=0)\n",
    "    sum_stds += np.std(rearrange(np.asarray(img), 'c h w -> (h w) c'), axis=0)\n",
    "sum_means / n, sum_stds / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6303db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum_means, sum_stds = np.asarray([0., 0., 0.]), np.asarray([0., 0., 0.])\n",
    "# n = 10000\n",
    "# ct = HE_color_transform()\n",
    "# for fp in np.random.choice(tcia_v_fps, size=n):\n",
    "#     img = torch.tensor(np.asarray(default_loader(fp)))\n",
    "# #     img = ct(img).numpy()\n",
    "#     img = img.numpy()\n",
    "#     sum_means += np.mean(rearrange(np.asarray(img), 'h w c -> (h w) c'), axis=0)\n",
    "#     sum_stds += np.std(rearrange(np.asarray(img), 'h w c -> (h w) c'), axis=0)\n",
    "# sum_means / n / 255., sum_stds / n / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0172226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum_means, sum_stds = np.asarray([0., 0., 0.]), np.asarray([0., 0., 0.])\n",
    "# n = 10000\n",
    "# ct = HE_color_transform()\n",
    "# for fp in np.random.choice(inhouse_v_fps, size=n):\n",
    "#     img = torch.tensor(np.asarray(default_loader(fp)))\n",
    "# #     img = ct(img).numpy()\n",
    "#     img = img.numpy()\n",
    "#     sum_means += np.mean(rearrange(np.asarray(img), 'h w c -> (h w) c'), axis=0)\n",
    "#     sum_stds += np.std(rearrange(np.asarray(img), 'h w c -> (h w) c'), axis=0)\n",
    "# sum_means / n / 255., sum_stds / n / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from violet.utils.dino_utils import DataAugmentationDINOMultichannel, HE_color_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "inhouse = transforms.Normalize(\n",
    "    (0.26181996, 0.59005849, 0.32784506), (0.16256156, 0.16977168, 0.15752241)\n",
    ")\n",
    "tcia = transforms.Normalize(\n",
    "    (0.24834598, 0.47750344, 0.35384849), (0.12277239, 0.14210545, 0.12420313)\n",
    ")\n",
    "r = transforms.Compose([\n",
    "    transforms.Resize((224, 224), interpolation=3),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "hec = HE_color_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d210e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "for fp in np.random.choice(inhouse_fps, size=n):\n",
    "    for i in range(10):\n",
    "        img = default_loader(fp)\n",
    "        img = r(img)\n",
    "        img = hec(img)\n",
    "        plt.imshow(rescale_intensity(rearrange(img.numpy(), 'c h w -> h w c'), out_range=(0., 1.)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bccb655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0743cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "ct = HE_color_transform()\n",
    "for fp in np.random.choice(inhouse_fps, size=n):\n",
    "    img = default_loader(fp)\n",
    "    img = r(img)\n",
    "    print(img.shape)\n",
    "    \n",
    "    print('raw')\n",
    "    plt.imshow(rearrange(img.numpy(), 'c h w -> h w c'))\n",
    "    plt.show()\n",
    "    \n",
    "    print('aug')\n",
    "    aug = hec(img)\n",
    "    plt.imshow(rescale_intensity(rearrange(aug.numpy(), 'c h w -> h w c'), out_range=(0., 1.)))\n",
    "    plt.show()\n",
    "    \n",
    "    print(torch.max(aug))\n",
    "    \n",
    "    print('aug inhouse norm')\n",
    "#     img_inhouse = hec(img)\n",
    "    img_inhouse = inhouse(aug)\n",
    "    plt.imshow(rescale_intensity(rearrange(img_inhouse.numpy(), 'c h w -> h w c'), out_range=(0., 1.)))\n",
    "    plt.show()    \n",
    "    \n",
    "    print('aug tcia norm')\n",
    "    img_tcia = tcia(aug)\n",
    "    plt.imshow(rescale_intensity(rearrange(img_tcia.numpy(), 'c h w -> h w c'), out_range=(0., 1.)))\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63135ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "ct = HE_color_transform()\n",
    "for fp in np.random.choice(tcia_fps, size=n):\n",
    "    img = default_loader(fp)\n",
    "    img = r(img)\n",
    "    print(img.shape)\n",
    "    \n",
    "    print('raw')\n",
    "    plt.imshow(rearrange(img.numpy(), 'c h w -> h w c'))\n",
    "    plt.show()\n",
    "    \n",
    "    print('aug')\n",
    "    aug = hec(img)\n",
    "    plt.imshow(rescale_intensity(rearrange(aug.numpy(), 'c h w -> h w c'), out_range=(0., 1.)))\n",
    "    plt.show()\n",
    "    \n",
    "    print(torch.max(aug))\n",
    "    \n",
    "    print('aug inhouse norm')\n",
    "#     img_inhouse = hec(img)\n",
    "    img_inhouse = inhouse(aug)\n",
    "    plt.imshow(rescale_intensity(rearrange(img_inhouse.numpy(), 'c h w -> h w c'), out_range=(0., 1.)))\n",
    "    plt.show()    \n",
    "    \n",
    "    print('aug tcia norm')\n",
    "    img_tcia = tcia(aug)\n",
    "    plt.imshow(rescale_intensity(rearrange(img_tcia.numpy(), 'c h w -> h w c'), out_range=(0., 1.)))\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb061757",
   "metadata": {},
   "outputs": [],
   "source": [
    "he = dino_he_transform_with_aug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "for fp in np.random.choice(inhouse_fps, size=n):\n",
    "    img = default_loader(fp)\n",
    "    plt.imshow(np.asarray(img))\n",
    "    plt.show()\n",
    "    for i in range(10):\n",
    "        img = default_loader(fp)\n",
    "        img = he(img)\n",
    "        plt.imshow(rescale_intensity(rearrange(img.numpy(), 'c h w -> h w c'), out_range=(0., 1.)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be43088c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "for fp in np.random.choice(inhouse_fps, size=n):\n",
    "    img = default_loader(fp)\n",
    "    plt.imshow(np.asarray(img))\n",
    "    plt.show()\n",
    "    for i in range(10):\n",
    "        img = default_loader(fp)\n",
    "        img = he(img)\n",
    "        plt.imshow(rescale_intensity(rearrange(img.numpy(), 'c h w -> h w c'), out_range=(0., 1.)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ddc98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 1\n",
    "for fp in np.random.choice(tcia_fps, size=n):\n",
    "    img = default_loader(fp)\n",
    "    plt.imshow(np.asarray(img))\n",
    "    plt.show()\n",
    "    for i in range(10):\n",
    "        img = default_loader(fp)\n",
    "        img = he(img)\n",
    "        plt.imshow(rescale_intensity(rearrange(img.numpy(), 'c h w -> h w c'), out_range=(0., 1.)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507fa67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "for fp in np.random.choice(tcia_fps, size=n):\n",
    "    img = default_loader(fp)\n",
    "    plt.imshow(np.asarray(img))\n",
    "    plt.show()\n",
    "    for i in range(10):\n",
    "        img = default_loader(fp)\n",
    "        img = he(img)\n",
    "        plt.imshow(rescale_intensity(rearrange(img.numpy(), 'c h w -> h w c'), out_range=(0., 1.)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b4d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
