{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52637feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import uuid\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import tifffile\n",
    "from PIL import Image, ImageOps\n",
    "from einops import rearrange\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aa1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e62c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56bdcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e7d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from violet.utils.dataloaders import listfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a012a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = sorted(listfiles('/data/violet/sandbox/tcia_pda_run1/st/normalized/'))\n",
    "len(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e420b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only 1x and 4x\n",
    "fps = [fp for fp in fps if '1.jpeg' in fp or '4.jpeg' in fp]\n",
    "len(fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e28602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b62335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05fa53f",
   "metadata": {},
   "source": [
    "###### data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0721bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b769dc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from timm.data.auto_augment import RandAugment, rand_augment_ops\n",
    "\n",
    "model = timm.create_model('efficientnetv2_s', num_classes=0)\n",
    "config = resolve_data_config({}, model=model)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619b5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/data/violet/sandbox/tcia_pda_run1/st/train_v2'\n",
    "val_dir = '/data/violet/sandbox/tcia_pda_run1/st/val_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41230419",
   "metadata": {},
   "outputs": [],
   "source": [
    "_RAND_TRANSFORMS = [\n",
    "    'AutoContrast',\n",
    "    'Equalize',\n",
    "    'Invert',\n",
    "    'Rotate',\n",
    "    'Posterize',\n",
    "    'Solarize',\n",
    "    'SolarizeAdd',\n",
    "    'Color',\n",
    "    'Contrast',\n",
    "    'Brightness',\n",
    "    'Sharpness',\n",
    "#     'ShearX',\n",
    "#     'ShearY',\n",
    "#     'TranslateXRel',\n",
    "#     'TranslateYRel',\n",
    "    #'Cutout'  # NOTE I've implement this as random erasing separately\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90520bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_transform(resize=(288, 288)):\n",
    "    return transforms.Compose((\n",
    "        transforms.Resize(resize),\n",
    "        RandAugment(rand_augment_ops(transforms=_RAND_TRANSFORMS), num_layers=2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.76806694, 0.47375619, 0.58864233), (0.17746654, 0.21851493, 0.18837758))\n",
    "    ))\n",
    "\n",
    "def get_val_transform(resize=(288, 288)):\n",
    "    return transforms.Compose((\n",
    "        transforms.Resize(resize),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.76806694, 0.47375619, 0.58864233), (0.17746654, 0.21851493, 0.18837758))\n",
    "    ))\n",
    "\n",
    "def get_filepath_map(root_dir, resolution=('1', '4'), regex=r'.jpeg$'):\n",
    "    fps = list(listfiles(root_dir, regex=regex))\n",
    "    fps = [fp for fp in fps if fp.split('.')[-2][-1] in resolution]\n",
    "    d = {}\n",
    "    for fp in fps:\n",
    "        fname = fp.split('/')[-1].split('.')[0]\n",
    "        sample = re.sub(r'^(.*)_[0-9]+$', r'\\1', fname)\n",
    "        res = re.sub(r'^.*_([0-9]+)$', r'\\1', fname)\n",
    "        \n",
    "        if sample not in d:\n",
    "            d[sample] = {}\n",
    "        d[sample][res] = fp\n",
    "    d = {k:v for k, v in d.items() if len(v)==len(resolution)}\n",
    "    return d\n",
    "        \n",
    "\n",
    "class MultiresDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, val_transform=None,\n",
    "                 resolution=('1', '4'), img_regex=r'.jpeg$', transform_prob=.8):\n",
    "        self.root_dir = root_dir\n",
    "        self.resolution = resolution\n",
    "        self.transform = get_training_transform() if transform is None else transform\n",
    "        self.transform_prob = transform_prob\n",
    "        self.val_transform = get_val_transform() if val_transform is None else val_transform\n",
    "        \n",
    "        self.filepath_map = get_filepath_map(self.root_dir, resolution=resolution, regex=img_regex)\n",
    "        self.samples = list(self.filepath_map.keys())\n",
    "        target_df = pd.read_csv(os.path.join(root_dir, 'targets.txt'), sep='\\t', index_col=0)\n",
    "        #normalize between 0-1\n",
    "        target_df = pd.DataFrame(data=target_df.values / np.max(target_df.values, axis=0),\n",
    "                                 columns=target_df.columns, index=target_df.index)\n",
    "        self.target_df = target_df.loc[self.samples]\n",
    "        self.target_labels = self.target_df.columns\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepath_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        d = self.filepath_map[sample]\n",
    "        img_dict = {f'{k}x':Image.open(fp) for k, fp in d.items()}\n",
    "        img_dict = {k:self.transform(img) if np.random.choice(\n",
    "                    [True, False], size=1, p=[self.transform_prob, 1-self.transform_prob]) else self.val_transform(img)\n",
    "                    for k, img in img_dict.items()}\n",
    "        return {\n",
    "            'sample': sample,\n",
    "            'images': img_dict,\n",
    "            'targets': self.target_df.values[idx]\n",
    "        }\n",
    "    \n",
    "class MultiresPredictionDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, resolution=('1', '4'), img_regex=r'.jpeg$'):\n",
    "        self.root_dir = root_dir\n",
    "        self.resolution = resolution\n",
    "        self.transform = get_training_transform() if transform is None else transform\n",
    "        \n",
    "        self.filepath_map = get_filepath_map(self.root_dir, resolution=resolution, regex=img_regex)\n",
    "        self.samples = list(self.filepath_map.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filepath_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        d = self.filepath_map[sample]\n",
    "        img_dict = {f'{k}x':Image.open(fp) for k, fp in d.items()}\n",
    "        img_dict = {k:self.transform(img) for k, img in img_dict.items()}\n",
    "        return {\n",
    "            'sample': sample,\n",
    "            'images': img_dict,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8750e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform, val_transform = get_training_transform(), get_val_transform()\n",
    "train_ds = MultiresDataset(train_dir, transform=train_transform)\n",
    "val_ds = MultiresDataset(val_dir, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023bef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls = [len(d['images']) for d in train_ds]\n",
    "# from collections import Counter\n",
    "# Counter(ls).most_common()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb88ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037b29f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_dl = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dba55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(train_dl))\n",
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2336532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b['images']['1x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d519296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity\n",
    "def display_tensor(x):\n",
    "    x = rearrange(x.numpy(), 'c h w -> h w c')\n",
    "    x = rescale_intensity(x, out_range=(0., 1.))\n",
    "    plt.imshow(x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73227563",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    display_tensor(b['images']['1x'][i])\n",
    "    display_tensor(b['images']['4x'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e308ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b = next(iter(val_dl))\n",
    "for i in range(10):\n",
    "    display_tensor(b['images']['1x'][i])\n",
    "    display_tensor(b['images']['4x'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3081188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed45ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05cea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce68b94e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9960c69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca45b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiresRegressor(torch.nn.Module):\n",
    "    def __init__(self, n_out, n_in=1280*2, h=516):\n",
    "        super(MultiresRegressor, self).__init__()\n",
    "        \n",
    "        self.stem_local = timm.create_model('efficientnetv2_s', num_classes=0)\n",
    "        self.stem_global = timm.create_model('efficientnetv2_s', num_classes=0)\n",
    "        \n",
    "        self.linear1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(n_in, h),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout()\n",
    "        )\n",
    "        self.linear2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(h, h),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.final = torch.nn.Sequential(\n",
    "            torch.nn.Linear(h, n_out),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_local, x_global):\n",
    "        local_out = self.stem_local(x_local)\n",
    "        global_out = self.stem_global(x_global)\n",
    "        x = torch.cat((local_out, global_out), dim=1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ad520",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d17aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiresRegressor(len(train_ds.target_labels))\n",
    "model = model.cuda()\n",
    "lr = 5e-4\n",
    "epochs = 10\n",
    "# opt = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    opt, max_lr=lr,\n",
    "    steps_per_epoch=len(train_dl), epochs=epochs)\n",
    "#RMSProp optimizer with decay 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618affb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_performance(train_se, val_se):\n",
    "    if isinstance(train_se, torch.Tensor):\n",
    "        train_se, val_se = train_se.detach().cpu().numpy(), val_se.detach().cpu().numpy()\n",
    "        \n",
    "    x = np.vstack((train_se, val_se))\n",
    "    df = pd.DataFrame(data=x, columns=train_ds.target_labels, index=['train', 'val'])\n",
    "    sns.heatmap(df)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd3e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_performance(np.random.rand(len(train_ds.target_labels)),\n",
    "#                 np.random.rand(len(train_ds.target_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7009e0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "criteria = torch.nn.MSELoss()\n",
    "for epoch in range(epochs):\n",
    "    train_loss, val_loss = 0., 0.\n",
    "    start = time.time()\n",
    "    train_se = torch.zeros(len(train_dl), len(train_ds.target_labels))\n",
    "    val_se = torch.zeros(len(val_dl), len(val_ds.target_labels))\n",
    "    model.train()\n",
    "    for i, b in enumerate(train_dl):\n",
    "        \n",
    "        x_local, x_global, y = b['images']['1x'].cuda(), b['images']['4x'].cuda(), b['targets'].cuda()\n",
    "        y = y.type(torch.float32)\n",
    "        logits = model(x_local, x_global)\n",
    "        loss = criteria(logits, y)\n",
    "        train_se[i] = torch.sum(torch.square(logits - y), dim=0)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        train_loss += loss\n",
    "        scheduler.step()\n",
    "    time_delta = time.time() - start\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, b in enumerate(val_dl):\n",
    "            x_local, x_global, y = b['images']['1x'].cuda(), b['images']['4x'].cuda(), b['targets'].cuda()\n",
    "            y = y.type(torch.float32)\n",
    "            logits = model(x_local, x_global)\n",
    "            loss = criteria(logits, y)\n",
    "            val_se[i] = torch.sum(torch.square(logits - y), dim=0)\n",
    "\n",
    "            val_loss += loss\n",
    "\n",
    "    train_loss /= len(train_dl)\n",
    "    val_loss /= len(val_dl)\n",
    "    plot_performance(torch.mean(train_se, dim=0), torch.mean(val_se, dim=0))\n",
    "    e_lr = opt.param_groups[0]['lr']\n",
    "    print(f'epoch: {epoch}, train loss: {train_loss}, val loss: {val_loss}, time: {time_delta}, lr: {e_lr}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b411181",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/data/violet/sandbox/tcia_pda_run1/st/models'\n",
    "Path(model_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a81dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(model_dir, 'st_10ep'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiresRegressor(len(train_ds.target_labels))\n",
    "model = model.cuda()\n",
    "checkpoint = torch.load(os.path.join(model_dir, 'st_10ep'))\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b41672",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ds = MultiresDataset(train_dir, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223add21",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dl = DataLoader(\n",
    "    a_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9764e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred_df = None\n",
    "with torch.no_grad():\n",
    "    for i, b in enumerate(a_dl):\n",
    "        x_local, x_global, y = b['images']['1x'].cuda(), b['images']['4x'].cuda(), b['targets'].cuda()\n",
    "        y = y.type(torch.float32)\n",
    "        logits = model(x_local, x_global)\n",
    "        df = pd.DataFrame(data=logits.detach().cpu().numpy(), columns=train_ds.target_labels,\n",
    "                          index=b['sample'])\n",
    "        if pred_df is None:\n",
    "            pred_df = df\n",
    "        else:\n",
    "            pred_df = pd.concat((pred_df, df), axis=0)\n",
    "        \n",
    "    for i, b in enumerate(val_dl):\n",
    "        x_local, x_global, y = b['images']['1x'].cuda(), b['images']['4x'].cuda(), b['targets'].cuda()\n",
    "        y = y.type(torch.float32)\n",
    "        logits = model(x_local, x_global)\n",
    "        df = pd.DataFrame(data=logits.detach().cpu().numpy(), columns=train_ds.target_labels,\n",
    "                          index=b['sample'])\n",
    "        if pred_df is None:\n",
    "            pred_df = df\n",
    "        else:\n",
    "            pred_df = pd.concat((pred_df, df), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeb715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d095660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439fae58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ae33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'HT270P1_S1H1Fs5U1'\n",
    "a = sc.read_visium(f'/data/spatial_transcriptomics/spaceranger_outputs/pancreatic/HT270P1-S1H1Fs5U1Bp1/')\n",
    "a.obs.index = [f'{s}_{x}' for x in a.obs.index]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.loc[[x for x in a.obs.index.to_list() if x in pred_df.index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4497d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b5a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gene in pred_df.columns:\n",
    "    a.obs[f'predicted_{gene}'] = [pred_df.loc[x, gene] if x in pred_df.index else 0. for x in a.obs.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c4b32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f707dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff3c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(a, color='predicted_PTPRC', alpha_img=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a53b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(a, color='predicted_CD8A', alpha_img=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b58954",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(a, color='predicted_EPCAM', alpha_img=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e991028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(a, color='predicted_BGN', alpha_img=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(a, color='predicted_PRSS1', alpha_img=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5448a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'HT264P1_S1H2Fs1_U1'\n",
    "a = sc.read_visium(f'/data/spatial_transcriptomics/spaceranger_outputs/pancreatic/HT264P1-S1H2Fs1U1Bp1/')\n",
    "a.obs.index = [f'{s}_{x}' for x in a.obs.index]\n",
    "\n",
    "for gene in pred_df.columns:\n",
    "    a.obs[f'predicted_{gene}'] = [pred_df.loc[x, gene] if x in pred_df.index else 0. for x in a.obs.index]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b199fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.log1p(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71edd77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(a, color=['PTPRC', 'predicted_PTPRC',\n",
    "                       'EPCAM', 'predicted_EPCAM',\n",
    "                       'BGN', 'predicted_BGN'], alpha_img=0., ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b071433",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(a, color=['EPCAM', 'predicted_EPCAM'], alpha_img=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4676ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(a, color=['BGN', 'predicted_BGN'], alpha_img=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86519bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.spatial(a, color='PTPRC', alpha_img=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a578e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c19781",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = list(listfiles('/data/violet/sandbox/tcia_pda_run1/tcia/raw/C3L-00017-21/', regex=r'.jpeg$'))\n",
    "len(fps), fps[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b276d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ds = MultiresPredictionDataset('/data/violet/sandbox/tcia_pda_run1/tcia/raw/C3L-00017-21/', transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ds = MultiresPredictionDataset('/data/violet/sandbox/tcia_pda_run1/tcia/raw/C3L-00401-22/', transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f06a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dl = DataLoader(\n",
    "    a_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307be54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a_ds), a_ds.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd9106",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred_df = None\n",
    "with torch.no_grad():\n",
    "    for i, b in enumerate(a_dl):\n",
    "        x_local, x_global = b['images']['1x'].cuda(), b['images']['4x'].cuda()\n",
    "        y = y.type(torch.float32)\n",
    "        logits = model(x_local, x_global)\n",
    "        df = pd.DataFrame(data=logits.detach().cpu().numpy(), columns=train_ds.target_labels,\n",
    "                          index=b['sample'])\n",
    "        if pred_df is None:\n",
    "            pred_df = df\n",
    "        else:\n",
    "            pred_df = pd.concat((pred_df, df), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d6c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37b4052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from violet.utils.analysis import display_2d_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45570d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in pred_df.columns:\n",
    "    print(h)\n",
    "    display_2d_scatter(pred_df, h)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4cc2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_2d_scatter(pred_df, 'PTPRC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f48e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_2d_scatter(pred_df, 'EPCAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e3fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_2d_scatter(pred_df, 'BGN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d7fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86094df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "region = [(-115, -90), (60, 85)]\n",
    "for h in pred_df.columns:\n",
    "    print(h)\n",
    "    display_2d_scatter(pred_df, h, region=region, scale=.015)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8b82b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112e5b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba85827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3014f21e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ef4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4982499f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10c1325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24385c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a1fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29dc575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eab1a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f89778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfd946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf0c084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a747b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e5bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf53a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('efficientnetv2_s', num_classes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a5d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 288, 288)\n",
    "x = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517111a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 288, 288)\n",
    "x = model.forward_features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa66fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8cdd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b3b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "config = resolve_data_config({}, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2dc765",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015a218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac374c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e74c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad892803",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiresDataset(Dataset):\n",
    "    def __init__(self, fps, transform=None):\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
